input: "img0"
input: "img1"
input_shape {
  dim: 1
  dim: 3
  dim: 448
  dim: 448
}
input_shape {
  dim: 1
  dim: 3
  dim: 448
  dim: 448
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "img0"
  top: "img0_Normalized"
  eltwise_param {
    operation: SUM
    coeff: 0.00392156862745
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "img1"
  top: "img1_Normalized"
  eltwise_param {
    operation: SUM
    coeff: 0.00392156862745
  }
}

#layer {  name: "img0_Normalized"  type: "Input"  top: "img0_Normalized"  input_param { shape: { dim: 1 dim: 3 dim: 448 dim: 448 } }}
#layer {  name: "img1_Normalized"  type: "Input"  top: "img1_Normalized"  input_param { shape: { dim: 1 dim: 3 dim: 448 dim: 448 } }}

################################################################################################################
											#adjxy#
################################################################################################################

##conv1
layer {  name: "adjxy_conv1"  type: "Convolution"  bottom: "img0_Normalized"  top: "adjxy_conv1"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 0.2    decay_mult: 0  }
  convolution_param {    num_output: 64    pad: 1    kernel_size: 3  
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN}}
layer {  name: "adjxy_relu1"  type: "ReLU"  bottom: "adjxy_conv1"  top: "adjxy_conv1"  relu_param {negative_slope: 0.1}}

##pool1
layer {  name: "adjxy_pool1"  type: "Pooling"  bottom: "adjxy_conv1"  top: "adjxy_pool1"
  pooling_param {   pool: MAX    kernel_size: 2    stride: 2  }}

##conv2
layer {  name: "adjxy_conv2"  type: "Convolution"  bottom: "adjxy_pool1"  top: "adjxy_conv2"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 0.2    decay_mult: 0  }
  convolution_param {    num_output: 128    pad: 1    kernel_size: 3  
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN}}
layer {  name: "adjxy_relu2"  type: "ReLU"  bottom: "adjxy_conv2"  top: "adjxy_conv2"  relu_param {negative_slope: 0.1}}

##pool2
layer {  name: "adjxy_pool2"  type: "Pooling"  bottom: "adjxy_conv2"  top: "adjxy_pool2"
  pooling_param {    pool: MAX    kernel_size: 2    stride: 2  }}
	
#conv3
layer {  bottom: "adjxy_pool2"  top: "adjxy_conv3"  name: "adjxy_conv3"  type: "Convolution"
  param {  lr_mult: 1   decay_mult: 1 }
  param {  lr_mult: 0.2   decay_mult: 0 }
  convolution_param {  num_output: 256    pad: 1    kernel_size: 3  
  weight_filler {type: "msra"}  bias_filler { type: "constant" }} }
layer {  bottom: "adjxy_conv3"  top: "adjxy_conv3"  name: "adjxy_relu3"  type: "ReLU"  relu_param {negative_slope: 0.1}}

##pool2
layer {  name: "adjxy_pool3"  type: "Pooling"  bottom: "adjxy_conv3"  top: "adjxy_pool3"
  pooling_param {    pool: MAX    kernel_size: 2    stride: 2  }}
##############################adjxy deconvolution################

############################ 3

layer {name: "adjxym_1_conv_3"  type: "Convolution" bottom: "adjxy_pool3"  top: "adjxym_1_conv_3"  
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 128  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {name: "relu_adjxym_1_conv_3"  type: "ReLU"  bottom: "adjxym_1_conv_3"  top: "adjxym_1_conv_3"   relu_param {negative_slope: 0.1}}
  
##adjxy_deconv3
layer {    name: "adjxy_deconv3"  type: "Deconvolution"  bottom: "adjxym_1_conv_3"  top: "adjxy_deconv3"
  param {  lr_mult: 0.01  decay_mult: 0.01  }
  convolution_param {	num_output: 128	group: 2	kernel_size: 4	stride: 2	pad: 1
	weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN }}
layer {  name: "adjxy_relu_deconv2"  type: "ReLU"  bottom: "adjxy_deconv3"  top: "adjxy_deconv3"  relu_param {negative_slope: 0.1}}

	
layer {  bottom: "adjxy_deconv3"  top: "adjxym_2_conv_3"  name: "adjxym_2_conv_3"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 64  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer { name: "bn_adjxym_2_conv_3" bottom: "adjxym_2_conv_3" top: "adjxym_2_conv_3"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer { name: "bn_adjxym_2_conv_3" bottom: "adjxym_2_conv_3" top: "adjxym_2_conv_3"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjxym_2_conv_3"  top: "adjxym_2_conv_3"  name: "relu_adjxym_2_conv_3"  type: "ReLU"  relu_param {negative_slope: 0.1}}

#######
layer {  bottom: "adjxy_conv3"  top: "adjxys_1_deconv_3"  name: "adjxys_1_deconv_3"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 64  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {  bottom: "adjxys_1_deconv_3"  top: "adjxys_1_deconv_3"  name: "bn_adjxys_1_deconv_3"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer {  bottom: "adjxys_1_deconv_3"  top: "adjxys_1_deconv_3"  name: "bn_adjxys_1_deconv_3"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjxys_1_deconv_3"  top: "adjxys_1_deconv_3"   name: "relu_adjxys_1_deconv_3"  type: "ReLU"  relu_param {negative_slope: 0.1}}

# concatenate two feature map
layer {  name: "adjxy_concat3"  bottom: "adjxys_1_deconv_3"  bottom: "adjxym_2_conv_3"  top: "adjxy_concat3"  type: "Concat"
  concat_param {  concat_dim: 1 }}
############################ 2	
layer { bottom: "adjxy_concat3"  top: "adjxym_1_conv_2"  name: "adjxym_1_conv_2"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 64  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {name: "relu_adjxym_1_conv_2"  type: "ReLU"  bottom: "adjxym_1_conv_2"  top: "adjxym_1_conv_2"   relu_param {negative_slope: 0.1}}

  
##adjxy_deconv2
layer {    name: "adjxy_deconv2"  type: "Deconvolution"  bottom: "adjxym_1_conv_2"  top: "adjxy_deconv2"
  param {  lr_mult: 0.01  decay_mult: 0.01  }
  convolution_param {	num_output: 64	group: 2	kernel_size: 4	stride: 2	pad: 1
	weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN }}
layer {  name: "adjxy_relu_deconv2"  type: "ReLU"  bottom: "adjxy_deconv2"  top: "adjxy_deconv2"  relu_param {negative_slope: 0.1}}
		
layer {  bottom: "adjxy_deconv2"  top: "adjxym_2_conv_2"  name: "adjxym_2_conv_2"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 32  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer { name: "bn_adjxym_2_conv_2" bottom: "adjxym_2_conv_2" top: "adjxym_2_conv_2"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer { name: "bn_adjxym_2_conv_2" bottom: "adjxym_2_conv_2" top: "adjxym_2_conv_2"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjxym_2_conv_2"  top: "adjxym_2_conv_2"  name: "relu_adjxym_2_conv_2"  type: "ReLU"  relu_param {negative_slope: 0.1}}

#######
layer {  bottom: "adjxy_conv2"  top: "adjxys_1_deconv_2"  name: "adjxys_1_deconv_2"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 32  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {  bottom: "adjxys_1_deconv_2"  top: "adjxys_1_deconv_2"  name: "bn_adjxys_1_deconv_2"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer {  bottom: "adjxys_1_deconv_2"  top: "adjxys_1_deconv_2"  name: "bn_adjxys_1_deconv_2"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjxys_1_deconv_2"  top: "adjxys_1_deconv_2"   name: "relu_adjxys_1_deconv_2"  type: "ReLU"  relu_param {negative_slope: 0.1}}

# concatenate two feature map
layer {  name: "adjxy_concat2"  bottom: "adjxys_1_deconv_2"  bottom: "adjxym_2_conv_2"  top: "adjxy_concat2"  type: "Concat"
  concat_param {  concat_dim: 1 }}  
############################ 1

	
layer { bottom: "adjxy_concat2"  top: "adjxym_1_conv_1"  name: "adjxym_1_conv_1"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 32 pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {  bottom: "adjxym_1_conv_1"  top: "adjxym_1_conv_1"  name: "relu_adjxym_1_conv_1"  type: "ReLU"  relu_param {negative_slope: 0.1}}
  
##adjxy_deconv1
layer {    name: "adjxy_deconv1"  type: "Deconvolution"  bottom: "adjxym_1_conv_1"  top: "adjxy_deconv1"
  param {  lr_mult: 0.01  decay_mult: 0.01  }
  convolution_param {	num_output: 32	group: 2	kernel_size: 4	stride: 2	pad: 1
	weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN }}
layer {  name: "adjxy_relu_deconv1"  type: "ReLU"  bottom: "adjxy_deconv1"  top: "adjxy_deconv1"  relu_param {negative_slope: 0.1}}
	
	
layer {  bottom: "adjxy_deconv1"  top: "adjxym_2_conv_1"  name: "adjxym_2_conv_1"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 16  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer { name: "bn_adjxym_2_conv_1" bottom: "adjxym_2_conv_1" top: "adjxym_2_conv_1"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer { name: "bn_adjxym_2_conv_1" bottom: "adjxym_2_conv_1" top: "adjxym_2_conv_1"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjxym_2_conv_1"  top: "adjxym_2_conv_1"  name: "relu_adjxym_2_conv_1"  type: "ReLU"  relu_param {negative_slope: 0.1}}

#######
layer {  bottom: "adjxy_conv1"  top: "adjxys_1_deconv_1"  name: "adjxys_1_deconv_1"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 16  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {  bottom: "adjxys_1_deconv_1"  top: "adjxys_1_deconv_1"  name: "bn_adjxys_1_deconv_1"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer {  bottom: "adjxys_1_deconv_1"  top: "adjxys_1_deconv_1"  name: "bn_adjxys_1_deconv_1"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjxys_1_deconv_1"  top: "adjxys_1_deconv_1"   name: "relu_adjxys_1_deconv_1"  type: "ReLU"  relu_param {negative_slope: 0.1}}

# concatenate two feature map
layer {  name: "adjxy_concat1"  bottom: "adjxys_1_deconv_1"  bottom: "adjxym_2_conv_1"  top: "adjxy_concat1"  type: "Concat"
  concat_param {  concat_dim: 1 }}

#################################################			

layer {  name: "adjxy_conv_out"  type: "Convolution"  bottom: "adjxy_concat1"  top: "adjxy_conv_out"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 2    decay_mult: 0  }
  convolution_param {    num_output: 2  pad: 1    kernel_size: 3	
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN  }}
layer {  bottom: "adjxy_conv_out"  top: "adjxy_conv_out"  name: "bn_adjxy_conv_out"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer {  bottom: "adjxy_conv_out"  top: "adjxy_conv_out"  name: "bn_adjxy_conv_out"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  name: "adjxy_relu_out"  type: "ReLU"  bottom: "adjxy_conv_out"  top: "adjxy_conv_out"  relu_param {negative_slope: 0.1}}


################################################################################################################
											#adjt#
################################################################################################################

layer {  name: "adjt_input"  type: "Concat"  bottom: "img0_Normalized"  bottom: "img1_Normalized"  top: "adjt_input"}

##conv1
layer {  name: "adjt_conv1"  type: "Convolution"  bottom: "adjt_input"  top: "adjt_conv1"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 0.2    decay_mult: 0  }
  convolution_param {    num_output: 64    pad: 1    kernel_size: 3  
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN}}
layer {  name: "adjt_relu1"  type: "ReLU"  bottom: "adjt_conv1"  top: "adjt_conv1"  relu_param {negative_slope: 0.1}}

##pool1
layer {  name: "adjt_pool1"  type: "Pooling"  bottom: "adjt_conv1"  top: "adjt_pool1"
  pooling_param {   pool: MAX    kernel_size: 2    stride: 2  }}

##conv2
layer {  name: "adjt_conv2"  type: "Convolution"  bottom: "adjt_pool1"  top: "adjt_conv2"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 0.2    decay_mult: 0  }
  convolution_param {    num_output: 128    pad: 1    kernel_size: 3  
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN}}
layer {  name: "adjt_relu2"  type: "ReLU"  bottom: "adjt_conv2"  top: "adjt_conv2"  relu_param {negative_slope: 0.1}}

##pool2
layer {  name: "adjt_pool2"  type: "Pooling"  bottom: "adjt_conv2"  top: "adjt_pool2"
  pooling_param {    pool: MAX    kernel_size: 2    stride: 2  }}
	
#conv3
layer {  bottom: "adjt_pool2"  top: "adjt_conv3"  name: "adjt_conv3"  type: "Convolution"
  param {  lr_mult: 1   decay_mult: 1 }
  param {  lr_mult: 0.2   decay_mult: 0 }
  convolution_param {  num_output: 256    pad: 1    kernel_size: 3  
  weight_filler {type: "msra"}  bias_filler { type: "constant" }} }
layer {  bottom: "adjt_conv3"  top: "adjt_conv3"  name: "adjt_relu3"  type: "ReLU"  relu_param {negative_slope: 0.1}}

##pool2
layer {  name: "adjt_pool3"  type: "Pooling"  bottom: "adjt_conv3"  top: "adjt_pool3"
  pooling_param {    pool: MAX    kernel_size: 2    stride: 2  }}
  
  
######################################temporal reasoning#################################
#conv1x1
layer {  bottom: "adjt_pool3"  top: "adjt_conv1_1x1"  name: "adjt_conv1_1x1"  type: "Convolution"
  param {  lr_mult: 1   decay_mult: 1 }
  param {  lr_mult: 0.2   decay_mult: 0 }
  convolution_param {  num_output: 256   pad: 0    kernel_size: 1  
  weight_filler {type: "msra"}  bias_filler { type: "constant" }} }
layer {  bottom: "adjt_conv1_1x1"  top: "adjt_conv1_1x1"  name: "adjt_relu1_1x1"  type: "ReLU"  relu_param {negative_slope: 0.1}}

layer {  bottom: "adjt_conv1_1x1"  top: "adjt_conv2_1x1"  name: "adjt_conv2_1x1"  type: "Convolution"
  param {  lr_mult: 1   decay_mult: 1 }
  param {  lr_mult: 0.2   decay_mult: 0 }
  convolution_param {  num_output: 512   pad: 0    kernel_size: 1  
  weight_filler {type: "msra"}  bias_filler { type: "constant" }} }
layer {  bottom: "adjt_conv2_1x1"  top: "adjt_conv2_1x1"  name: "adjt_relu2_1x1"  type: "ReLU"  relu_param {negative_slope: 0.1}}

layer {  bottom: "adjt_conv2_1x1"  top: "adjt_conv3_1x1"  name: "adjt_conv3_1x1"  type: "Convolution"
  param {  lr_mult: 1   decay_mult: 1 }
  param {  lr_mult: 0.2   decay_mult: 0 }
  convolution_param {  num_output: 1024    pad: 0    kernel_size: 1  
  weight_filler {type: "msra"}  bias_filler { type: "constant" }} }
layer {  bottom: "adjt_conv3_1x1"  top: "adjt_conv3_1x1"  name: "adjt_relu3_1x1"  type: "ReLU"  relu_param {negative_slope: 0.1}}

layer {  bottom: "adjt_conv3_1x1"  top: "adjt_conv4_1x1"  name: "adjt_conv4_1x1"  type: "Convolution"
  param {  lr_mult: 1   decay_mult: 1 }
  param {  lr_mult: 0.2   decay_mult: 0 }
  convolution_param {  num_output: 512   pad: 0    kernel_size: 1  
  weight_filler {type: "msra"}  bias_filler { type: "constant" }} }
layer {  bottom: "adjt_conv4_1x1"  top: "adjt_conv4_1x1"  name: "adjt_relu4_1x1"  type: "ReLU"  relu_param {negative_slope: 0.1}}

layer {  bottom: "adjt_conv4_1x1"  top: "adjt_conv5_1x1"  name: "adjt_conv5_1x1"  type: "Convolution"
  param {  lr_mult: 1   decay_mult: 1 }
  param {  lr_mult: 0.2   decay_mult: 0 }
  convolution_param {  num_output: 256    pad: 0    kernel_size: 1  
  weight_filler {type: "msra"}  bias_filler { type: "constant" }} }
layer {  bottom: "adjt_conv5_1x1"  top: "adjt_conv5_1x1"  name: "adjt_relu5_1x1"  type: "ReLU"  relu_param {negative_slope: 0.1}}
##############################adjt deconvolution################

############################ 3

layer {name: "adjtm_1_conv_3"  type: "Convolution" bottom: "adjt_conv5_1x1"  top: "adjtm_1_conv_3"  
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 128  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {name: "relu_adjtm_1_conv_3"  type: "ReLU"  bottom: "adjtm_1_conv_3"  top: "adjtm_1_conv_3"   relu_param {negative_slope: 0.1}}
  
##adjt_deconv3
layer {    name: "adjt_deconv3"  type: "Deconvolution"  bottom: "adjtm_1_conv_3"  top: "adjt_deconv3"
  param {  lr_mult: 0.01  decay_mult: 0.01  }
  convolution_param {	num_output: 128	group: 2	kernel_size: 4	stride: 2	pad: 1
	weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN }}
layer {  name: "adjt_relu_deconv2"  type: "ReLU"  bottom: "adjt_deconv3"  top: "adjt_deconv3"  relu_param {negative_slope: 0.1}}

	
layer {  bottom: "adjt_deconv3"  top: "adjtm_2_conv_3"  name: "adjtm_2_conv_3"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 64  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer { name: "bn_adjtm_2_conv_3" bottom: "adjtm_2_conv_3" top: "adjtm_2_conv_3"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer { name: "bn_adjtm_2_conv_3" bottom: "adjtm_2_conv_3" top: "adjtm_2_conv_3"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjtm_2_conv_3"  top: "adjtm_2_conv_3"  name: "relu_adjtm_2_conv_3"  type: "ReLU"  relu_param {negative_slope: 0.1}}

#######
layer {  bottom: "adjt_conv3"  top: "adjts_1_deconv_3"  name: "adjts_1_deconv_3"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 64  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {  bottom: "adjts_1_deconv_3"  top: "adjts_1_deconv_3"  name: "bn_adjts_1_deconv_3"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer {  bottom: "adjts_1_deconv_3"  top: "adjts_1_deconv_3"  name: "bn_adjts_1_deconv_3"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjts_1_deconv_3"  top: "adjts_1_deconv_3"   name: "relu_adjts_1_deconv_3"  type: "ReLU"  relu_param {negative_slope: 0.1}}

# concatenate two feature map
layer {  name: "adjt_concat3"  bottom: "adjts_1_deconv_3"  bottom: "adjtm_2_conv_3"  top: "adjt_concat3"  type: "Concat"
  concat_param {  concat_dim: 1 }}
############################ 2	
layer { bottom: "adjt_concat3"  top: "adjtm_1_conv_2"  name: "adjtm_1_conv_2"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 64  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {name: "relu_adjtm_1_conv_2"  type: "ReLU"  bottom: "adjtm_1_conv_2"  top: "adjtm_1_conv_2"   relu_param {negative_slope: 0.1}}

  
##adjt_deconv2
layer {    name: "adjt_deconv2"  type: "Deconvolution"  bottom: "adjtm_1_conv_2"  top: "adjt_deconv2"
  param {  lr_mult: 0.01  decay_mult: 0.01  }
  convolution_param {	num_output: 64	group: 2	kernel_size: 4	stride: 2	pad: 1
	weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN }}
layer {  name: "adjt_relu_deconv2"  type: "ReLU"  bottom: "adjt_deconv2"  top: "adjt_deconv2"  relu_param {negative_slope: 0.1}}
		
layer {  bottom: "adjt_deconv2"  top: "adjtm_2_conv_2"  name: "adjtm_2_conv_2"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 32  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer { name: "bn_adjtm_2_conv_2" bottom: "adjtm_2_conv_2" top: "adjtm_2_conv_2"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer { name: "bn_adjtm_2_conv_2" bottom: "adjtm_2_conv_2" top: "adjtm_2_conv_2"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjtm_2_conv_2"  top: "adjtm_2_conv_2"  name: "relu_adjtm_2_conv_2"  type: "ReLU"  relu_param {negative_slope: 0.1}}

#######
layer {  bottom: "adjt_conv2"  top: "adjts_1_deconv_2"  name: "adjts_1_deconv_2"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 32  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {  bottom: "adjts_1_deconv_2"  top: "adjts_1_deconv_2"  name: "bn_adjts_1_deconv_2"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer {  bottom: "adjts_1_deconv_2"  top: "adjts_1_deconv_2"  name: "bn_adjts_1_deconv_2"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjts_1_deconv_2"  top: "adjts_1_deconv_2"   name: "relu_adjts_1_deconv_2"  type: "ReLU"  relu_param {negative_slope: 0.1}}

# concatenate two feature map
layer {  name: "adjt_concat2"  bottom: "adjts_1_deconv_2"  bottom: "adjtm_2_conv_2"  top: "adjt_concat2"  type: "Concat"
  concat_param {  concat_dim: 1 }}  
############################ 1

	
layer { bottom: "adjt_concat2"  top: "adjtm_1_conv_1"  name: "adjtm_1_conv_1"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 32 pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {  bottom: "adjtm_1_conv_1"  top: "adjtm_1_conv_1"  name: "relu_adjtm_1_conv_1"  type: "ReLU"  relu_param {negative_slope: 0.1}}
  
##adjt_deconv1
layer {    name: "adjt_deconv1"  type: "Deconvolution"  bottom: "adjtm_1_conv_1"  top: "adjt_deconv1"
  param {  lr_mult: 0.01  decay_mult: 0.01  }
  convolution_param {	num_output: 32	group: 2	kernel_size: 4	stride: 2	pad: 1
	weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN }}
layer {  name: "adjt_relu_deconv1"  type: "ReLU"  bottom: "adjt_deconv1"  top: "adjt_deconv1"  relu_param {negative_slope: 0.1}}
	
	
layer {  bottom: "adjt_deconv1"  top: "adjtm_2_conv_1"  name: "adjtm_2_conv_1"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 16  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer { name: "bn_adjtm_2_conv_1" bottom: "adjtm_2_conv_1" top: "adjtm_2_conv_1"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer { name: "bn_adjtm_2_conv_1" bottom: "adjtm_2_conv_1" top: "adjtm_2_conv_1"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 } include { phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjtm_2_conv_1"  top: "adjtm_2_conv_1"  name: "relu_adjtm_2_conv_1"  type: "ReLU"  relu_param {negative_slope: 0.1}}

#######
layer {  bottom: "adjt_conv1"  top: "adjts_1_deconv_1"  name: "adjts_1_deconv_1"  type: "Convolution"
  param {  lr_mult: 1  decay_mult: 1 }
  param {  lr_mult: 2  decay_mult: 0 }
  convolution_param {  num_output: 16  pad: 1  kernel_size: 3
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN } }
layer {  bottom: "adjts_1_deconv_1"  top: "adjts_1_deconv_1"  name: "bn_adjts_1_deconv_1"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer {  bottom: "adjts_1_deconv_1"  top: "adjts_1_deconv_1"  name: "bn_adjts_1_deconv_1"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  bottom: "adjts_1_deconv_1"  top: "adjts_1_deconv_1"   name: "relu_adjts_1_deconv_1"  type: "ReLU"  relu_param {negative_slope: 0.1}}

# concatenate two feature map
layer {  name: "adjt_concat1"  bottom: "adjts_1_deconv_1"  bottom: "adjtm_2_conv_1"  top: "adjt_concat1"  type: "Concat"
  concat_param {  concat_dim: 1 }}

#################################################			

layer {  name: "adjt_conv_out"  type: "Convolution"  bottom: "adjt_concat1"  top: "adjt_conv_out"
  param {    lr_mult: 1    decay_mult: 1  }
  param {    lr_mult: 2    decay_mult: 0  }
  convolution_param {    num_output: 1  pad: 1    kernel_size: 3	
  weight_filler {type: "msra"}  bias_filler { type: "constant" } engine: CUDNN  }}
layer {  bottom: "adjt_conv_out"  top: "adjt_conv_out"  name: "bn_adjt_conv_out"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TRAIN }
  batch_norm_param { use_global_stats: false } }
layer {  bottom: "adjt_conv_out"  top: "adjt_conv_out"  name: "bn_adjt_conv_out"  type: "BatchNorm"
  param { lr_mult: 0 }  param { lr_mult: 0 }  param { lr_mult: 0 }  include{ phase: TEST }
  batch_norm_param { use_global_stats: true } }
layer {  name: "adjt_relu_out"  type: "ReLU"  bottom: "adjt_conv_out"  top: "adjt_conv_out"  relu_param {negative_slope: 0.1}}


#####################################################################################################
                            #FlowNetS#
#####################################################################################################
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "adjt_conv_out"
  bottom: "adjxy_conv_out"
  top: "input"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "input"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "conv4"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "conv5"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "conv6"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "conv6_1"
  top: "predict_flow6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}

layer {
  name: "deconv5"
  type: "Deconvolution"
  bottom: "conv6_1"
  top: "deconv5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "deconv5"
  top: "deconv5"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "upsample_flow6to5"
  type: "Deconvolution"
  bottom: "predict_flow6"
  top: "upsampled_flow6_to_5"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "conv5_1"
  bottom: "deconv5"
  bottom: "upsampled_flow6_to_5"
  top: "concat5"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "concat5"
  top: "predict_flow5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}

layer {
  name: "deconv4"
  type: "Deconvolution"
  bottom: "concat5"
  top: "deconv4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "deconv4"
  top: "deconv4"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "upsample_flow5to4"
  type: "Deconvolution"
  bottom: "predict_flow5"
  top: "upsampled_flow5_to_4"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "conv4_1"
  bottom: "deconv4"
  bottom: "upsampled_flow5_to_4"
  top: "concat4"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "concat4"
  top: "predict_flow4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}

layer {
  name: "deconv3"
  type: "Deconvolution"
  bottom: "concat4"
  top: "deconv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "deconv3"
  top: "deconv3"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "upsample_flow4to3"
  type: "Deconvolution"
  bottom: "predict_flow4"
  top: "upsampled_flow4_to_3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "conv3_1"
  bottom: "deconv3"
  bottom: "upsampled_flow4_to_3"
  top: "concat3"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "concat3"
  top: "predict_flow3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}

layer {
  name: "deconv2"
  type: "Deconvolution"
  bottom: "concat3"
  top: "deconv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "deconv2"
  top: "deconv2"
  relu_param {
    negative_slope: 0.1
  }
}
layer {
  name: "upsample_flow3to2"
  type: "Deconvolution"
  bottom: "predict_flow3"
  top: "upsampled_flow3_to_2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 4
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "conv2"
  bottom: "deconv2"
  bottom: "upsampled_flow3_to_2"
  top: "concat2"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "concat2"
  top: "predict_flow2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
    engine: CUDNN
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "predict_flow2"
  top: "blob44"
  eltwise_param {
    operation: SUM
    coeff: 20.0
  }
}
layer {
  name: "Resample4"
  type: "Resample"
  bottom: "blob44"
  top: "predict_flow_resize"
  resample_param {
    width: 640
    height: 480
    type: LINEAR
    antialias: true
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "predict_flow_resize"
  top: "predict_flow_final"
  convolution_param {
    num_output: 2
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "diagonal"
      diag_val: 1
      diag_val: 1
    }
    bias_filler {
      type: "constant"
    }
  }
}



